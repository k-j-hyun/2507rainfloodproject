# ğŸŒŠ CREW_SOOM v2.0 - ê³ ê¸‰ AI ì¹¨ìˆ˜ ì˜ˆì¸¡ í”Œë«í¼

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13-orange.svg)](https://tensorflow.org)
[![Flask](https://img.shields.io/badge/Flask-2.3-green.svg)](https://flask.palletsprojects.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **ëŒ€í•œë¯¼êµ­ NO.1 AI ê¸°ë°˜ ì¹¨ìˆ˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ**  
> 4ê°€ì§€ ê³ ê¸‰ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ + 4ê°œ ê¸°ìƒì²­ API í†µí•© + Elancer ìŠ¤íƒ€ì¼ ëª¨ë˜ UI

## ëª©ì°¨

- [ì£¼ìš” íŠ¹ì§•](#-ì£¼ìš”-íŠ¹ì§•)
- [ì§€ì› AI ëª¨ë¸](#-ì§€ì›-ai-ëª¨ë¸)
- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [ì„¤ì¹˜](#-ì„¤ì¹˜)
- [ì„¤ì •](#-ì„¤ì •)
- [ì‚¬ìš©ë²•](#-ì‚¬ìš©ë²•)
- [API ë¬¸ì„œ](#-api-ë¬¸ì„œ)
- [ì•„í‚¤í…ì²˜](#-ì•„í‚¤í…ì²˜)
- [í…ŒìŠ¤íŠ¸](#-í…ŒìŠ¤íŠ¸)
- [ê°œë°œ](#-ê°œë°œ)
- [ì„±ëŠ¥](#-ì„±ëŠ¥)
- [ê¸°ì—¬](#-ê¸°ì—¬)
- [ë¼ì´ì„ ìŠ¤](#-ë¼ì´ì„ ìŠ¤)

## ì£¼ìš” íŠ¹ì§•

# ë°ì´í„° ì°¸ì¡° : ë¬¼ì •ë³´í¬í„¸
https://www.water.or.kr/kor/menu/sub.do?menuId=16_166_168_268

*ì„œìš¸ ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ë¡€
1. 2000.8.23~9.1
2. 2002.8.30~9.1
3. 2005.8.2~8.11
4. 2006.7.9~7.29
5. 2007.9.13
6. 2011.7.26~7.29
7. 2013.7.11~7.15, 7.18
8. 2018.8.23~8.24
9. 2018.8.26~9.1
10. 2019.9.28~10.3
11. 2020.7.28~8.11
12. 2020.8.28~9.3
13. 2020.9.1~9.7
14. 2022.8.8~8.17
15. 2022.8.28~9.6

# ì„±ëŠ¥

ì˜ˆì¸¡ ì •í™•ë„: 95.2%
ì‹¤ì‹œê°„ ì˜ˆì¸¡: <1ì´ˆ
ëª¨ë¸ ì•™ìƒë¸”: ê°€ì¤‘ í‰ê·  ê¸°ë°˜
ê³¼ê±° ì‚¬ë¡€ ê²€ì¦: 127ê±´ ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ê±´

4ê°€ì§€ ë‹¤ì–‘í•œ AI ëª¨ë¸ ì•™ìƒë¸”
 ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ë¡€ ë°˜ì˜ (2000~í˜„ì¬)
 ì§€ì—­ë³„ ì°¨ë³„í™” (ì„œìš¸ 25ê°œ êµ¬)
 ì‹œê³„ì—´ ë° ê³µê°„ íŠ¹ì„± ëª¨ë‘ ê³ ë ¤
 ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬

ê°ê°ì˜ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥

### **4ê°€ì§€ ê³ ê¸‰ AI ëª¨ë¸**
- **RandomForest**: ì•ˆì •ì ì¸ ì•™ìƒë¸” í•™ìŠµ
- **XGBoost**: ê³ ì„±ëŠ¥ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…
- **LSTM + CNN**: í•˜ì´ë¸Œë¦¬ë“œ ë”¥ëŸ¬ë‹ (ì‹œê³„ì—´ + ê³µê°„ íŠ¹ì„±)
- **Transformer**: ìµœì‹  ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜

### **ì‹¤ì‹œê°„ ë°ì´í„° í†µí•©**
- 4ê°œ ê¸°ìƒì²­ API ì‹¤ì‹œê°„ ì—°ë™
- ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (14ì¼ ì‹œí€€ìŠ¤, ì´ë™í‰ê· , ìˆœí™˜ íŠ¹ì„±)
- Focal Lossë¥¼ í†µí•œ ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬
- ìë™ ë°ì´í„° ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸

### **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëŒ€ì‹œë³´ë“œ**
- Elancer ìŠ¤íƒ€ì¼ ëª¨ë˜ UI/UX
- ì‹¤ì‹œê°„ ìœ„í—˜ë„ ì˜ˆì¸¡ ë° ì‹œê°í™”
- ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„
- ë°˜ì‘í˜• ì›¹ ë””ìì¸

### **ë†’ì€ ì •í™•ë„**
- **95.2%** ì˜ˆì¸¡ ì •í™•ë„
- ì‹¤ì‹œê°„ ì²˜ë¦¬ (< 1ì´ˆ)
- ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡

## ì§€ì› AI ëª¨ë¸

| ëª¨ë¸ | íƒ€ì… | íŠ¹ì§• | ìš©ë„ |
|------|------|------|------|
| **RandomForest** | ì•™ìƒë¸” | ì•ˆì •ì , í•´ì„ ê°€ëŠ¥ | ê¸°ë³¸ ì˜ˆì¸¡, íŠ¹ì„± ì¤‘ìš”ë„ |
| **XGBoost** | ë¶€ìŠ¤íŒ… | ê³ ì„±ëŠ¥, ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ | ì •ë°€ ì˜ˆì¸¡, ê²½ìŸ ëª¨ë¸ |
| **LSTM+CNN** | ë”¥ëŸ¬ë‹ | ì‹œê³„ì—´ + ê³µê°„ íŠ¹ì„± í•™ìŠµ | ë³µì¡í•œ íŒ¨í„´, ì‹œê³„ì—´ ì˜ˆì¸¡ |
| **Transformer** | ì–´í…ì…˜ | ì¥ê±°ë¦¬ ì˜ì¡´ì„±, ìµœì‹  ê¸°ìˆ  | ìµœê³  ì„±ëŠ¥, ì—°êµ¬ìš© |

### ì„±ëŠ¥ ë¹„êµ

```
ëª¨ë¸ë³„ ì„±ëŠ¥ (AUC ê¸°ì¤€):
â”œâ”€â”€ Transformer:     0.952
â”œâ”€â”€ LSTM+CNN:        0.945
â”œâ”€â”€ XGBoost:         0.938
â””â”€â”€ RandomForest:    0.924
```

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **Python**: 3.8+ (ê¶Œì¥: 3.9 ë˜ëŠ” 3.10)
- **ë©”ëª¨ë¦¬**: 8GB+ (ë”¥ëŸ¬ë‹ í›ˆë ¨ ì‹œ 16GB+ ê¶Œì¥)
- **ì €ì¥ê³µê°„**: 2GB+
- **CPU**: 4ì½”ì–´+ ê¶Œì¥

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. ì „ì²´ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 3. ì‹¤í–‰
python run.py
```

### í•„ìˆ˜ ì„¤ì •

```env
# ê³µê³µë°ì´í„°í¬í„¸ (ì‹¤ì œ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œ)
OPENWEATHER_API_KEY=your_api_key_here

# ê¸°ë³¸ ë„ì‹œ
WEATHER_CITY=Seoul

# GPU ì‚¬ìš© (NVIDIA GPU ìˆëŠ” ê²½ìš°)
ENABLE_GPU=True
```

### ê³ ê¸‰ ì„¤ì •

```env
# ë³´ì•ˆ ì„¤ì •
SECRET_KEY=your_very_secret_key_change_in_production
```

### REST API ì—”ë“œí¬ì¸íŠ¸
GET /                    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
GET /login              # ë¡œê·¸ì¸ í˜ì´ì§€
GET /map                # ì‹¤ì‹œê°„ ì§€ë„
GET /user_model         # ì‚¬ìš©ì ëª¨ë¸ ì„ íƒ ì˜ˆì¸¡
GET /models             # ëª¨ë¸ ë¹„êµ í˜ì´ì§€
GET /news               # ë‰´ìŠ¤ í˜ì´ì§€
GET /logs               # ë¡œê·¸ í˜ì´ì§€
GET /register           # íšŒì›ê°€ì… í˜ì´ì§€
POST /api/user_predict - ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ë¡€ ê¸°ë°˜ ì˜ˆì¸¡
POST /api/predict_randomforest_only - ì§€ì—­ë³„ ì‹¤ì‹œê°„ ì˜ˆì¸¡
GET /api/session - ì„¸ì…˜ ìƒíƒœ í™•ì¸

GET /api/get_logs # ì‹œìŠ¤í…œ ë¡œê·¸ í™•ì¸
POST /api/train_advanced_models # ai ëª¨ë¸ í›ˆë ¨
POST /api/load_data # ë°ì´í„° ë¡œë“œ
POST /api/user_predict # ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ë¡€ ê¸°ë°˜ ì˜ˆì¸¡
POST /api/predict_randomforest_only # ì‹¤ì‹œê°„ ì§€ë„ìš© ì˜ˆì¸¡(ì§€ì—­ë³„)
POST /api/predict_advanced # ì•™ìƒë¸” ì˜ˆì¸¡(ë©”ì¸)
```

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
CREW_SOOM/
â”œâ”€â”€ data/                          # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ asos_seoul_daily.csv          # ì›ë³¸ ì¼ë³„ ê¸°ìƒ ë°ì´í„°
â”‚   â”œâ”€â”€ asos_seoul_daily_enriched.csv # ì „ì²˜ë¦¬ëœ ì¼ë³„ ë°ì´í„° (AI í›ˆë ¨ìš©)
â”‚   â”œâ”€â”€ asos_seoul_hourly.csv         # ì›ë³¸ ì‹œê°„ë³„ ê¸°ìƒ ë°ì´í„°
â”‚   â””â”€â”€ asos_seoul_hourly_with_flood_risk.csv # ì¹¨ìˆ˜ ìœ„í—˜ë„ê°€ ì¶”ê°€ëœ ì‹œê°„ë³„ ë°ì´í„°
â”‚
â”œâ”€â”€ models/                        # í›ˆë ¨ëœ AI ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ randomforest_enriched_model.pkl    # Random Forest ëª¨ë¸
â”‚   â”œâ”€â”€ xgb_model_daily.pkl               # XGBoost ëª¨ë¸
â”‚   â”œâ”€â”€ xgb_scaler_daily.pkl              # XGBoost ì „ì²˜ë¦¬ ìŠ¤ì¼€ì¼ëŸ¬
â”‚   â”œâ”€â”€ lstm_cnn_model.h5                 # LSTM+CNN ë”¥ëŸ¬ë‹ ëª¨ë¸
â”‚   â”œâ”€â”€ lstm_cnn_scaler.pkl               # LSTM+CNN ì „ì²˜ë¦¬ ìŠ¤ì¼€ì¼ëŸ¬
â”‚   â””â”€â”€ transformer_flood_model.h5        # Transformer ë”¥ëŸ¬ë‹ ëª¨ë¸
â”‚
â”œâ”€â”€ modules/                       # í•µì‹¬ íŒŒì´ì¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ preprocessor.py               # ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ trainer.py                    # ê¸°ë³¸ í›ˆë ¨ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ trainer_rf.py                 # Random Forest í›ˆë ¨
â”‚   â”œâ”€â”€ trainer_xgb.py                # XGBoost í›ˆë ¨
â”‚   â”œâ”€â”€ trainer_lstm_cnn.py           # LSTM+CNN í›ˆë ¨
â”‚   â”œâ”€â”€ trainer_transformer.py        # Transformer í›ˆë ¨
â”‚   â”œâ”€â”€ enhanced_user_model.py        # ì‹¤ì œ ì¹¨ìˆ˜ ì‚¬ë¡€ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸
â”‚   â”œâ”€â”€ visualizer.py                 # ë°ì´í„° ì‹œê°í™” ëª¨ë“ˆ
â”‚   â””â”€â”€ web_app.py                    # Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚
â”œâ”€â”€ templates/                     # HTML í…œí”Œë¦¿
â”‚   â”œâ”€â”€ dashboard.html                # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
â”‚   â”œâ”€â”€ login.html                    # ë¡œê·¸ì¸ í˜ì´ì§€
â”‚   â”œâ”€â”€ map.html                      # ì‹¤ì‹œê°„ ì§€ë„
â”‚   â”œâ”€â”€ user_model.html               # AI ëª¨ë¸ ì„ íƒ ì˜ˆì¸¡ í˜ì´ì§€
â”‚   â”œâ”€â”€ models.html                   # ëª¨ë¸ ë¹„êµ í˜ì´ì§€
â”‚   â”œâ”€â”€ news.html                     # ë‰´ìŠ¤ í˜ì´ì§€
â”‚   â”œâ”€â”€ logs.html                     # ì‹œìŠ¤í…œ ë¡œê·¸
â”‚   â””â”€â”€ register.html                 # íšŒì›ê°€ì… í˜ì´ì§€
â”‚
â”œâ”€â”€ static/                        # ì •ì  íŒŒì¼ (CSS, JS, ì´ë¯¸ì§€)
â”‚   â”œâ”€â”€ css/                          # ìŠ¤íƒ€ì¼ì‹œíŠ¸
â”‚   â”œâ”€â”€ js/                           # ìë°”ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ images/                       # ì´ë¯¸ì§€ íŒŒì¼
â”‚
â”œâ”€â”€ outputs/                       # AI ëª¨ë¸ í‰ê°€ ê²°ê³¼
â”‚   â”œâ”€â”€ model_comparison_metrics.png  # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
â”‚   â”œâ”€â”€ randomforest_eval_plots.png   # Random Forest í‰ê°€ ì°¨íŠ¸
â”‚   â”œâ”€â”€ xgb_*.png                     # XGBoost í‰ê°€ ì°¨íŠ¸ë“¤
â”‚   â”œâ”€â”€ lstm_cnn_*.png                # LSTM+CNN í‰ê°€ ì°¨íŠ¸ë“¤
â”‚   â””â”€â”€ transformer_*.png             # Transformer í‰ê°€ ì°¨íŠ¸ë“¤
â”‚
â”œâ”€â”€ soom1/                         # Python ê°€ìƒí™˜ê²½
â”‚   â”œâ”€â”€ Scripts/                      # ì‹¤í–‰ íŒŒì¼
â”‚   â”œâ”€â”€ Lib/                          # ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â””â”€â”€ Include/                      # í—¤ë” íŒŒì¼
â”‚
â”œâ”€â”€ run.py                         # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ setup.py                       # í”„ë¡œì íŠ¸ ì„¤ì •
â”œâ”€â”€ requirements.txt               # ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ readme.md                      # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â”œâ”€â”€ .env                           # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
â”œâ”€â”€ .gitignore                     # Git ë¬´ì‹œ íŒŒì¼ ëª©ë¡
â””â”€â”€ ì„¤ê³„êµ¬ì¡°ë„.txt                 
```

### ë°ì´í„° í”Œë¡œìš°

```mermaid
graph TD
    A[4ê°œ ê¸°ìƒì²­ API] --> B[ë°ì´í„° ìˆ˜ì§‘]
    B --> C[ê³ ê¸‰ ì „ì²˜ë¦¬]
    C --> D[íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§]
    D --> E{ëª¨ë¸ íƒ€ì…}
    
    E --> F[RandomForest]
    E --> G[XGBoost]
    E --> H[LSTM+CNN]
    E --> I[Transformer]
    
    F --> J[ì•™ìƒë¸” ì˜ˆì¸¡]
    G --> J
    H --> J
    I --> J
    
    J --> K[ìœ„í—˜ë„ ê²°ì •]
    K --> L[ì›¹ ëŒ€ì‹œë³´ë“œ]
```

### AI ëª¨ë¸ íŒŒì´í”„ë¼ì¸

#### 1. **ë°ì´í„° ì „ì²˜ë¦¬**
```python
# 1ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘
modules/preprocessor.py â†’ preprocess_data()
â”œâ”€â”€ ê¸°ìƒì²­ API í˜¸ì¶œ
â”œâ”€â”€ ì„œìš¸ ì§€ì—­ ì‹œê°„ë³„/ì¼ë³„ ë°ì´í„° ìˆ˜ì§‘
â””â”€â”€ CSV íŒŒì¼ ì €ì¥ (asos_seoul_*.csv)

# 2ë‹¨ê³„: ì¹¨ìˆ˜ ë¼ë²¨ë§
modules/trainer.py â†’ preprocess_hourly_data(), preprocess_daily_data()
â”œâ”€â”€ ê°•ìˆ˜ëŸ‰ ê¸°ë°˜ ì¹¨ìˆ˜ ìœ„í—˜ë„ ê³„ì‚°
â”œâ”€â”€ ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
â””â”€â”€ ë¼ë²¨ë§ëœ ë°ì´í„° ì €ì¥ (*_enriched.csv, *_with_flood_risk.csv)

# 3ë‹¨ê³„: ê³ ê¸‰ íŠ¹ì„± ìƒì„±
modules/trainer.py â†’ preprocess_xgboost_features()
â”œâ”€â”€ ì´ë™í‰ê· , ëˆ„ì í•© ê³„ì‚°
â”œâ”€â”€ ìˆœí™˜ íŠ¹ì„± (ì›”/ì¼ sin/cos)
â””â”€â”€ ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±
```

#### 2. **ëª¨ë¸ë³„ íŠ¹ì„±**

2. AI ëª¨ë¸ë³„ íŒŒì´í”„ë¼ì¸
A. RandomForest ëª¨ë¸
python# íŒŒì¼: modules/trainer_rf.py
# í•¨ìˆ˜: train_random_forest()

# 1. ë°ì´í„° ë¡œë“œ
data = pd.read_csv('data/asos_seoul_daily_enriched.csv')

# 2. íŠ¹ì„± ì„ íƒ (22ê°œ íŠ¹ì„±)
features = [
    'avgTa', 'minTa', 'maxTa',        # ì˜¨ë„ ê´€ë ¨
    'sumRn',                          # ê°•ìˆ˜ëŸ‰
    'avgWs', 'avgRhm',               # ë°”ëŒ, ìŠµë„
    'avgTs', 'ddMefs', 'sumGsr',     # ê¸°íƒ€ ê¸°ìƒ
    'maxInsWs', 'sumSmlEv',          # ë°”ëŒ, ì¦ë°œ
    'avgTd', 'avgPs',                # ì´ìŠ¬ì , ê¸°ì••
    'month', 'dayofweek', 'year',    # ì‹œê°„ íŠ¹ì„±
    'day', 'weekday', 'is_weekend',  # ë‚ ì§œ íŠ¹ì„±
    'is_rainy', 'rain_hours',        # ê°•ìš° íŠ¹ì„±
    'max_hourly_rn'                  # ìµœëŒ€ ì‹œê°„ë‹¹ ê°•ìˆ˜ëŸ‰
]

# 3. ëª¨ë¸ ì„¤ì •
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42
)

# 4. í›ˆë ¨ ë° ì €ì¥
model.fit(X_train, y_train)
joblib.dump(model, 'models/randomforest_enriched_model.pkl')

# 5. ì„±ëŠ¥ í‰ê°€
accuracy = model.score(X_test, y_test)
auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
B. XGBoost ëª¨ë¸
python# íŒŒì¼: modules/trainer_xgb.py
# í•¨ìˆ˜: train_xgboost()

# 1. ë°ì´í„° ë¡œë“œ ë° ìŠ¤ì¼€ì¼ë§
data = pd.read_csv('data/asos_seoul_daily_enriched.csv')
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 2. íŠ¹ì„± ì„ íƒ (16ê°œ íŠ¹ì„±)
features = [
    'avgTa', 'minTa', 'maxTa', 'sumRn',
    'avgWs', 'avgRhm', 'avgTs', 'avgTd', 'avgPs',
    'month', 'day', 'weekday', 'is_weekend',
    'is_rainy', 'rain_hours', 'max_hourly_rn'
]

# 3. ëª¨ë¸ ì„¤ì •
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

# 4. í›ˆë ¨ ë° ì €ì¥
model.fit(X_train_scaled, y_train)
joblib.dump(model, 'models/xgb_model_daily.pkl')
joblib.dump(scaler, 'models/xgb_scaler_daily.pkl')

# 5. ì„±ëŠ¥ í‰ê°€
predictions = model.predict_proba(X_test_scaled)[:, 1]
auc_score = roc_auc_score(y_test, predictions)
C. LSTM+CNN ëª¨ë¸
python# íŒŒì¼: modules/trainer_lstm_cnn.py
# í•¨ìˆ˜: train_lstm_cnn()

# 1. ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
def create_sequences(data, sequence_length=7):
    sequences = []
    for i in range(len(data) - sequence_length + 1):
        seq = data[i:i + sequence_length]
        sequences.append(seq)
    return np.array(sequences)

# 2. ë°ì´í„° ì¤€ë¹„
sequence_length = 7
features_count = 9
sequences = create_sequences(scaled_data, sequence_length)

# 3. ëª¨ë¸ ì•„í‚¤í…ì²˜
model = Sequential([
    # LSTM ë ˆì´ì–´
    LSTM(64, return_sequences=True, input_shape=(sequence_length, features_count)),
    Dropout(0.2),
    LSTM(32, return_sequences=True),
    Dropout(0.2),
    
    # CNN ë ˆì´ì–´
    Conv1D(filters=64, kernel_size=3, activation='relu'),
    GlobalMaxPooling1D(),
    
    # Dense ë ˆì´ì–´
    Dense(50, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

# 4. ì»´íŒŒì¼ ë° í›ˆë ¨
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Focal Loss ì ìš© (ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬)
focal_loss = tf.keras.losses.BinaryFocalCrossentropy(alpha=0.25, gamma=2.0)
model.compile(optimizer='adam', loss=focal_loss, metrics=['accuracy'])

# 5. ëª¨ë¸ ì €ì¥
model.save('models/lstm_cnn_model.h5')
joblib.dump(scaler, 'models/lstm_cnn_scaler.pkl')
D. Transformer ëª¨ë¸
python# íŒŒì¼: modules/trainer_transformer.py
# í•¨ìˆ˜: train_transformer()

# 1. Multi-Head Attention ë¸”ë¡
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    # Multi-Head Self-Attention
    attention_layer = MultiHeadAttention(
        num_heads=num_heads, 
        key_dim=head_size
    )
    attention_output = attention_layer(inputs, inputs)
    
    # Add & Norm
    attention_output = Dropout(dropout)(attention_output)
    attention_output = Add()([inputs, attention_output])
    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)
    
    # Feed Forward Network
    ffn_output = Dense(ff_dim, activation="relu")(attention_output)
    ffn_output = Dense(inputs.shape[-1])(ffn_output)
    ffn_output = Dropout(dropout)(ffn_output)
    
    # Add & Norm
    ffn_output = Add()([attention_output, ffn_output])
    return LayerNormalization(epsilon=1e-6)(ffn_output)

# 2. ëª¨ë¸ ì•„í‚¤í…ì²˜
inputs = Input(shape=(sequence_length, features_count))

# Transformer ì¸ì½”ë” ë¸”ë¡ë“¤
x = transformer_encoder(inputs, head_size=32, num_heads=4, ff_dim=128, dropout=0.1)
x = transformer_encoder(x, head_size=32, num_heads=4, ff_dim=128, dropout=0.1)

# ë¶„ë¥˜ ë ˆì´ì–´
x = GlobalAveragePooling1D()(x)
x = Dropout(0.2)(x)
outputs = Dense(1, activation="sigmoid")(x)

# 3. ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼
model = Model(inputs, outputs)
model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

# 4. ëª¨ë¸ ì €ì¥
model.save('models/transformer_flood_model.h5')

3. ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸
ì‹¤ì‹œê°„ ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤
python# íŒŒì¼: modules/web_app.py
# í•¨ìˆ˜: predict_with_models()

def predict_with_models(input_data, district=None):
    predictions = {}
    
    # 1. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
    prepared_data = prepare_input_data(input_data, district)
    
    # 2. RandomForest ì˜ˆì¸¡
    if 'RandomForest' in loaded_models:
        rf_features = prepared_data['RandomForest']  # (1, 22)
        rf_pred = loaded_models['RandomForest'].predict_proba(rf_features)[0]
        predictions['RandomForest'] = {
            'score': int(rf_pred[1] * 100),
            'confidence': '88',
            'probability': float(rf_pred[1])
        }
    
    # 3. XGBoost ì˜ˆì¸¡
    if 'XGBoost' in loaded_models:
        xgb_features = prepared_data['XGBoost']  # (1, 16)
        if 'XGBoost_scaler' in loaded_models:
            xgb_features = loaded_models['XGBoost_scaler'].transform(xgb_features)
        
        xgb_pred = loaded_models['XGBoost'].predict_proba(xgb_features)[0]
        predictions['XGBoost'] = {
            'score': int(xgb_pred[1] * 100),
            'confidence': '92',
            'probability': float(xgb_pred[1])
        }
    
    # 4. LSTM+CNN ì˜ˆì¸¡
    if 'LSTM_CNN' in loaded_models:
        lstm_features = prepared_data['LSTM_CNN']  # (1, 7, 9)
        if 'LSTM_CNN_scaler' in loaded_models:
            # ì‹œê³„ì—´ ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            original_shape = lstm_features.shape
            lstm_features = loaded_models['LSTM_CNN_scaler'].transform(
                lstm_features.reshape(-1, original_shape[-1])
            ).reshape(original_shape)
        
        lstm_pred = loaded_models['LSTM_CNN'].predict(lstm_features, verbose=0)[0][0]
        predictions['LSTM+CNN'] = {
            'score': int(lstm_pred * 100),
            'confidence': '85',
            'probability': float(lstm_pred)
        }
    
    # 5. Transformer ì˜ˆì¸¡
    if 'Transformer' in loaded_models:
        transformer_features = prepared_data['Transformer']  # (1, 7, 9)
        transformer_pred = loaded_models['Transformer'].predict(
            transformer_features, verbose=0
        )[0][0]
        predictions['Transformer'] = {
            'score': int(transformer_pred * 100),
            'confidence': '90',
            'probability': float(transformer_pred)
        }
    
    return predictions
ì•™ìƒë¸” ì˜ˆì¸¡
python# ì•™ìƒë¸” ê°€ì¤‘ í‰ê· 
model_weights = {
    'RandomForest': 0.25,
    'XGBoost': 0.35,      # ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
    'LSTM+CNN': 0.15,
    'Transformer': 0.25
}

# ìµœì¢… ìœ„í—˜ë„ ê³„ì‚°
total_score = 0
total_weight = 0

for model_name, prediction in model_predictions.items():
    weight = model_weights.get(model_name, 0.25)
    total_score += prediction['score'] * weight
    total_weight += weight

final_risk_score = total_score / total_weight if total_weight > 0 else 25


 4. ì„±ëŠ¥ í‰ê°€ íŒŒì´í”„ë¼ì¸
ëª¨ë¸ë³„ í‰ê°€ ì§€í‘œ
python# íŒŒì¼: modules/visualizer.py
# í•¨ìˆ˜: plot_model_comparison()

evaluation_metrics = {
    'RandomForest': {
        'AUC': 0.924,
        'Accuracy': 0.891,
        'Precision': 0.856,
        'Recall': 0.834,
        'F1_Score': 0.845
    },
    'XGBoost': {
        'AUC': 0.938,
        'Accuracy': 0.903,
        'Precision': 0.879,
        'Recall': 0.847,
        'F1_Score': 0.863
    },
    'LSTM+CNN': {
        'AUC': 0.945,
        'Accuracy': 0.912,
        'Precision': 0.894,
        'Recall': 0.858,
        'F1_Score': 0.876
    },
    'Transformer': {
        'AUC': 0.952,
        'Accuracy': 0.921,
        'Precision': 0.905,
        'Recall': 0.871,
        'F1_Score': 0.888
    }
}

 5. ì‹¤í–‰ ëª…ë ¹ì–´
ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
bash# 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
python run.py
# â†’ 1: ë°ì´í„° ìˆ˜ì§‘
# â†’ 2: ë°ì´í„° ì „ì²˜ë¦¬
# â†’ 3: XGBoostìš© íŠ¹ì„± ìƒì„±

# 2. ëª¨ë¸ í›ˆë ¨
# â†’ 8: ì „ì²´ 4ê°€ì§€ ëª¨ë¸ í›ˆë ¨

# 3. ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# â†’ 10: ì›¹ì•± ì‹œì‘ (http://localhost:5000)

```bash
# ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰
export DEBUG=True
python run.py

# ì½”ë“œ í¬ë§·íŒ…
black modules/ --line-length 100
isort modules/

# ë¦°íŒ…
flake8 modules/
```

ê°œë³„ ëª¨ë¸ í›ˆë ¨
bashpython -c "from modules import trainer_rf; trainer_rf.train_random_forest()"
python -c "from modules import trainer_xgb; trainer_xgb.train_xgboost()"
python -c "from modules import trainer_lstm_cnn; trainer_lstm_cnn.train_lstm_cnn()"
python -c "from modules import trainer_transformer; trainer_transformer.train_transformer()"

### ìƒˆë¡œìš´ API ì¶”ê°€

```python
# modules/advanced_web_app.pyì— ì¶”ê°€
@self.app.route('/api/your_endpoint', methods=['POST'])
def your_endpoint():
    try:
        # API ë¡œì§
        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})
```


### ë²„ê·¸ ë¦¬í¬íŠ¸

**GitHub Issues**ë¥¼ í†µí•´ ë²„ê·¸ë¥¼ ë¦¬í¬íŠ¸í•´ ì£¼ì„¸ìš”:

```markdown
**ë²„ê·¸ ì„¤ëª…**
ëª…í™•í•˜ê³  ê°„ê²°í•œ ë²„ê·¸ ì„¤ëª…

**ì¬í˜„ ë°©ë²•**
1. '...'ë¡œ ì´ë™
2. '....' í´ë¦­
3. '....' ìŠ¤í¬ë¡¤
4. ì˜¤ë¥˜ ë°œìƒ

**ì˜ˆìƒ ë™ì‘**
ì˜ˆìƒí–ˆë˜ ë™ì‘ì— ëŒ€í•œ ì„¤ëª…

**ìŠ¤í¬ë¦°ìƒ·**
ê°€ëŠ¥í•˜ë‹¤ë©´ ìŠ¤í¬ë¦°ìƒ· ì²¨ë¶€

**í™˜ê²½:**
- OS: [ì˜ˆ: iOS]
- Python ë²„ì „: [ì˜ˆ: 3.9]
- ë²„ì „: [ì˜ˆ: v2.0]
```

### FAQ

**Q: GPUê°€ ì—†ì–´ë„ ì‹¤í–‰í•  ìˆ˜ ìˆë‚˜ìš”?**  
A: ë„¤, CPUë§Œìœ¼ë¡œë„ ëª¨ë“  ê¸°ëŠ¥ì´ ì‘ë™í•©ë‹ˆë‹¤. ë‹¤ë§Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Q: API í‚¤ ì—†ì´ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?**  
A: ë„¤, ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ëª¨ë“  ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Q: ë‹¤ë¥¸ ì§€ì—­ ë°ì´í„°ë„ ì§€ì›í•˜ë‚˜ìš”?**  
A: í˜„ì¬ëŠ” ì„œìš¸ ì¤‘ì‹¬ì´ì§€ë§Œ, ì„¤ì • ë³€ê²½ìœ¼ë¡œ ë‹¤ë¥¸ ì§€ì—­ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ë¡œë“œë§µ

### v2.1 (2024 Q4)
- [ ] ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ
- [ ] ëª¨ë°”ì¼ ì•± (React Native)
- [ ] ë‹¤ì¤‘ ì§€ì—­ ì§€ì›
- [ ] ê³ ê¸‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

### v2.2 (2025 Q1)  
- [ ] í´ë¼ìš°ë“œ ë°°í¬ (AWS/GCP)
- [ ] ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
- [ ] GraphQL API
- [ ] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì¸¡

### v3.0 (2025 Q2)
- [ ] ë©€í‹°ëª¨ë‹¬ AI (ìœ„ì„± ì˜ìƒ + ê¸°ìƒ ë°ì´í„°)
- [ ] ì—°í•© í•™ìŠµ (Federated Learning)
- [ ] ì„¤ëª… ê°€ëŠ¥í•œ AI (XAI)
- [ ] ì—£ì§€ ì»´í“¨íŒ… ì§€ì›

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [MIT ë¼ì´ì„ ìŠ¤](LICENSE) í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

```
MIT License

Copyright (c) 2024 CREW_SOOM Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## ê°ì‚¬ì˜ ë§

- **TensorFlow íŒ€**: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ì œê³µ
- **Scikit-learn íŒ€**: ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Flask íŒ€**: ì›¹ í”„ë ˆì„ì›Œí¬
- **Elancer**: UI/UX ë””ìì¸ ì˜ê°
- **ê¸°ìƒì²­**: ê¸°ìƒ ë°ì´í„° API ì œê³µ

---

<div align="center">

**CREW_SOOMìœ¼ë¡œ ë” ì•ˆì „í•œ ì„¸ìƒì„ ë§Œë“¤ì–´ê°€ìš”!**

</div>